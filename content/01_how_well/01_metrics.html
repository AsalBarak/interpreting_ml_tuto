<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>1.1. Metrics to judge the sucess of a model &#8212; Tutorial</title>
    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     'may 2018',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/copybutton.js"></script>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="1.2. Cross-validation: some gotchas" href="02_cross_validation.html" />
    <link rel="prev" title="1. Measuring how well a model predicts" href="index.html" />
   
    <link rel="stylesheet"
	  href="https://unpkg.com/purecss@1.0.0/build/base-min.css">

<script type="text/javascript">
$(function () {
    // Highlight the table of content as we scroll
    sections = {},
    i        = 0,
    url	 = document.URL.replace(/#.*$/, ""),
    current_section = 0;

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50;
    });

    $(window).scroll(function(event) {
	var pos   = $(window).scrollTop();

	// Highlight the current section
	$('a.internal').parent().removeClass('active');
        for(i in sections){
            if(sections[i] > pos){
		break;
            };
	    if($('a.internal[href$="' + i + '"]').is(':visible')){
		current_section = i;
	    };
        }
	$('a.internal[href$="' + current_section + '"]').parent().addClass('active');
	$('a.internal[href$="' + current_section + '"]').parent().parent().parent().addClass('active');
	$('a.internal[href$="' + current_section + '"]').parent().parent().parent().parent().parent().addClass('active');
    });

});
</script>


  </head>
  <body role="document">
   <!-- Use the header to add javascript -->
    

    <script type="text/javascript">
    // Function to collapse the tip divs
    function collapse_tip_div(obj){
	// Update the representation on the tip div based on whether it
	// has the 'collapsed' css class or not: we only want to
	// collapse divs that are not already collapsed
	if($(obj).hasClass("collapsed")) {
	} else {
	    $(obj).find("p.summary").remove();
	    var content = $(obj).text();
	    var html = $(obj).html();

	    if(content.length > 40) {
		if ($.browser.msie) {
		    // We start at '3' to avoid 'tip', as IE
		    // does not count whitespace
		    var content = content.substr(3, 50);
		} else {
		    // We start at '5' to avoid 'tip '
		    var content = content.substr(5, 50);
		}
	    }
	    $(obj).html('<p class="summary"><img src="../../_static/plus.png">' + content + '...</p>' + html);
	}
    }
    </script>

    <script type="text/javascript">
    $(function () {
	$(".tip")
	    .click(function(event){
		$(this).toggleClass("collapsed");
		// Change state of the global button
		$('div.related li.transparent').removeClass('transparent')
		$(this).find("p.summary").remove();
		if($(this).hasClass("collapsed")) {
		    var content = $(this).text();
		    var html = $(this).html();

		    if(content.length > 40) {
			if ($.browser.msie) {
			    // We start at '3' to avoid 'tip', as IE
			    // does not count whitespace
			    var content = content.substr(3, 50);
			} else {
			    // We start at '5' to avoid 'tip '
			    var content = content.substr(5, 50);
			}
		    }
		    $(this).html('<p class="summary"><img src="../../_static/plus.png">' + content + '...</p>' + html);
		}
		if (event.target.tagName.toLowerCase() != "a") {
                   return true; //Makes links clickable
		}
	});
    });
    </script>


    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="02_cross_validation.html" title="1.2. Cross-validation: some gotchas"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="index.html" title="1. Measuring how well a model predicts"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">Tutorial</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">1. Measuring how well a model predicts</a> &#187;</li>
     
    <!-- Insert a menu in the navigation bar -->
    <li class="left">
	<!-- On click toggle the 'tip' on or off-->
	<a onclick="$('.tip').each(function (index, obj) {
			    collapse_tip_div(obj);
		    });
		    $('.tip').addClass('collapsed');
		    $('.left').addClass('transparent');">
	<img src="../../_static/minus.png"
         alt="Collapse to compact view" style="padding: 1ex;"/>
	<span class="hiddenlink">Collapse document to compact view</span>
    </a></li>

      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-content-01-how-well-01-metrics-py"><span class="std std-ref">here</span></a> to download the full example code or run this example in your browser via Binder</p>
</div>
<div class="sphx-glr-example-title section" id="metrics-to-judge-the-sucess-of-a-model">
<span id="sphx-glr-content-01-how-well-01-metrics-py"></span><h1>1.1. Metrics to judge the sucess of a model<a class="headerlink" href="#metrics-to-judge-the-sucess-of-a-model" title="Permalink to this headline">¶</a></h1>
<p>Pro &amp; cons of various performance metrics.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#regression-settings" id="id2">Regression settings</a><ul>
<li><a class="reference internal" href="#the-boston-housing-data" id="id3">The Boston housing data</a></li>
<li><a class="reference internal" href="#explained-variance-vs-mean-square-error" id="id4">Explained variance vs Mean Square Error</a></li>
<li><a class="reference internal" href="#mean-squared-error-versus-mean-absolute-error" id="id5">Mean Squared Error versus Mean Absolute Error</a></li>
<li><a class="reference internal" href="#summary" id="id6">Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#classification-settings" id="id7">Classification settings</a><ul>
<li><a class="reference internal" href="#the-digits-data" id="id8">The digits data</a></li>
<li><a class="reference internal" href="#accuracy-and-its-shortcomings" id="id9">Accuracy and its shortcomings</a></li>
<li><a class="reference internal" href="#precision-recall-and-their-shortcomings" id="id10">Precision, recall, and their shortcomings</a></li>
<li><a class="reference internal" href="#area-under-the-roc-curve" id="id11">Area under the ROC curve</a></li>
<li><a class="reference internal" href="#average-precision" id="id12">Average precision</a></li>
<li><a class="reference internal" href="#multiclass-and-multilabel-settings" id="id13">Multiclass and multilabel settings</a></li>
<li><a class="reference internal" href="#id1" id="id14">Summary</a></li>
</ul>
</li>
</ul>
</div>
<p>The simple way to use a scoring metric during cross-validation is
via the <cite>scoring</cite> parameter of
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="(in scikit-learn v0.19.1)"><code class="xref py py-func docutils literal"><span class="pre">sklearn.model_selection.cross_val_score()</span></code></a>.</p>
<div class="section" id="regression-settings">
<h2><a class="toc-backref" href="#id2">1.1.1. Regression settings</a><a class="headerlink" href="#regression-settings" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-boston-housing-data">
<h3><a class="toc-backref" href="#id3">1.1.1.1. The Boston housing data</a><a class="headerlink" href="#the-boston-housing-data" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<div class="newline"></div><span class="n">boston</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_boston</span><span class="p">()</span>
<div class="newline"></div>
<div class="newline"></div><span class="c1"># Shuffle the data</span>
<div class="newline"></div><span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<div class="newline"></div><span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<div class="newline"></div></pre></div>
</div>
<p>A quick plot of how each feature is related to the target</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<div class="newline"></div>
<div class="newline"></div><span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">):</span>
<div class="newline"></div>    <a href="http://matplotlib.org/api/_as_gen/matplotlib.pyplot.figure.html#matplotlib.pyplot.figure" title="View documentation for matplotlib.pyplot.figure"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<div class="newline"></div>    <a href="http://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html#matplotlib.pyplot.scatter" title="View documentation for matplotlib.pyplot.scatter"><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span></a><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<div class="newline"></div>    <a href="http://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlabel.html#matplotlib.pyplot.xlabel" title="View documentation for matplotlib.pyplot.xlabel"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span></a><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>
<div class="newline"></div>    <a href="http://matplotlib.org/api/_as_gen/matplotlib.pyplot.ylabel.html#matplotlib.pyplot.ylabel" title="View documentation for matplotlib.pyplot.ylabel"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span></a><span class="p">(</span><span class="s1">&#39;Price (US$)&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>
<div class="newline"></div>    <a href="http://matplotlib.org/api/_as_gen/matplotlib.pyplot.tight_layout.html#matplotlib.pyplot.tight_layout" title="View documentation for matplotlib.pyplot.tight_layout"><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span></a><span class="p">()</span>
<div class="newline"></div></pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img alt="../../_images/sphx_glr_01_metrics_001.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_001.png" />
</li>
<li><img alt="../../_images/sphx_glr_01_metrics_002.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_002.png" />
</li>
<li><img alt="../../_images/sphx_glr_01_metrics_003.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_003.png" />
</li>
<li><img alt="../../_images/sphx_glr_01_metrics_004.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_004.png" />
</li>
<li><img alt="../../_images/sphx_glr_01_metrics_005.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_005.png" />
</li>
<li><img alt="../../_images/sphx_glr_01_metrics_006.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_006.png" />
</li>
<li><img alt="../../_images/sphx_glr_01_metrics_007.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_007.png" />
</li>
<li><img alt="../../_images/sphx_glr_01_metrics_008.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_008.png" />
</li>
<li><img alt="../../_images/sphx_glr_01_metrics_009.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_009.png" />
</li>
<li><img alt="../../_images/sphx_glr_01_metrics_010.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_010.png" />
</li>
<li><img alt="../../_images/sphx_glr_01_metrics_011.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_011.png" />
</li>
<li><img alt="../../_images/sphx_glr_01_metrics_012.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_012.png" />
</li>
<li><img alt="../../_images/sphx_glr_01_metrics_013.png" class="sphx-glr-multi-img first" src="../../_images/sphx_glr_01_metrics_013.png" />
</li>
</ul>
<p>We will be using a random forest regressor to predict the price</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<div class="newline"></div><span class="n">regressor</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>
<div class="newline"></div></pre></div>
</div>
</div>
<div class="section" id="explained-variance-vs-mean-square-error">
<h3><a class="toc-backref" href="#id4">1.1.1.2. Explained variance vs Mean Square Error</a><a class="headerlink" href="#explained-variance-vs-mean-square-error" title="Permalink to this headline">¶</a></h3>
<p>The default score is explained variance</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<div class="newline"></div><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.82931291</span>  <span class="mf">0.86444028</span>  <span class="mf">0.83677762</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>Explained variance is convienent because it has a natural scaling: 1 is
perfect prediction, and 0 is around chance</p>
<p>Now let us see which houses are easier to predict:</p>
<p>Not along the Charles river (feature 3)</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span>
<div class="newline"></div>                      <span class="n">target</span><span class="p">[</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.83035919</span>  <span class="mf">0.87916182</span>  <span class="mf">0.83339392</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>Along the Charles river</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span>
<div class="newline"></div>                      <span class="n">target</span><span class="p">[</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.58696309</span> <span class="o">-</span><span class="mf">0.10045637</span>  <span class="mf">0.75639362</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>So the houses along the Charles are harder to predict?</p>
<p>It&#8217;s not so easy to conclude this from the explained variance: in two
different sets of observations, the variance of the target differs, and
the explained variance is a relative measure</p>
<p><strong>MSE</strong>: We can use the mean squared error (here negated)</p>
<p>Not along the Charles river</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span>
<div class="newline"></div>                      <span class="n">target</span><span class="p">[</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span>
<div class="newline"></div>                      <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="o">-</span><span class="mf">14.9439586</span>   <span class="o">-</span><span class="mf">7.64191274</span> <span class="o">-</span><span class="mf">14.53927134</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>Along the Charles river</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span>
<div class="newline"></div>                      <span class="n">target</span><span class="p">[</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span>
<div class="newline"></div>                      <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="o">-</span><span class="mf">83.40058333</span> <span class="o">-</span><span class="mf">71.73003333</span> <span class="o">-</span><span class="mf">51.11090909</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>So the error is larger along the Charles river</p>
</div>
<div class="section" id="mean-squared-error-versus-mean-absolute-error">
<h3><a class="toc-backref" href="#id5">1.1.1.3. Mean Squared Error versus Mean Absolute Error</a><a class="headerlink" href="#mean-squared-error-versus-mean-absolute-error" title="Permalink to this headline">¶</a></h3>
<p>What if we want to report an error in dollars, meaningful for an
application?</p>
<p>The Mean Absolute Error is useful for this goal</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span>
<div class="newline"></div>                      <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_absolute_error&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="o">-</span><span class="mf">2.41680473</span> <span class="o">-</span><span class="mf">2.28349112</span> <span class="o">-</span><span class="mf">2.79029762</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
</div>
<div class="section" id="summary">
<h3><a class="toc-backref" href="#id6">1.1.1.4. Summary</a><a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><strong>explained variance</strong>: scaled with regards to chance: 1 = perfect,
0 = around chance, but it shouldn&#8217;t used to compare predictions
across datasets</li>
<li><strong>mean absolute error</strong>: enables comparison across datasets in the
units of the target</li>
</ul>
</div>
</div>
<div class="section" id="classification-settings">
<h2><a class="toc-backref" href="#id7">1.1.2. Classification settings</a><a class="headerlink" href="#classification-settings" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-digits-data">
<h3><a class="toc-backref" href="#id8">1.1.2.1. The digits data</a><a class="headerlink" href="#the-digits-data" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>
<div class="newline"></div><span class="c1"># Let us try to detect sevens:</span>
<div class="newline"></div><span class="n">sevens</span> <span class="o">=</span> <span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">7</span><span class="p">)</span>
<div class="newline"></div>
<div class="newline"></div><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<div class="newline"></div><span class="n">classifier</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<div class="newline"></div></pre></div>
</div>
</div>
<div class="section" id="accuracy-and-its-shortcomings">
<h3><a class="toc-backref" href="#id9">1.1.2.2. Accuracy and its shortcomings</a><a class="headerlink" href="#accuracy-and-its-shortcomings" title="Permalink to this headline">¶</a></h3>
<p>The default metric is the accuracy: the averaged fraction of success.
It takes values between 0 and 1, where 1 is perfect prediction</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">sevens</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.96833333</span>  <span class="mf">0.97161937</span>  <span class="mf">0.98662207</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>However, a stupid classifier can each good prediction wit imbalanced
classes</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>
<div class="newline"></div><span class="n">most_frequent</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">)</span>
<div class="newline"></div><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">most_frequent</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">sevens</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.9</span>         <span class="mf">0.89983306</span>  <span class="mf">0.90133779</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>Balanced accuracy (available in development scikit-learn versions)
fixes this, but can have surprising behaviors, such as being negative</p>
</div>
<div class="section" id="precision-recall-and-their-shortcomings">
<h3><a class="toc-backref" href="#id10">1.1.2.3. Precision, recall, and their shortcomings</a><a class="headerlink" href="#precision-recall-and-their-shortcomings" title="Permalink to this headline">¶</a></h3>
<p>We can measure separately false detection and misses</p>
<p><strong>Precision</strong>: Precision counts the ratio of detections that are
correct</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">sevens</span><span class="p">,</span>
<div class="newline"></div>                      <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;precision&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">1.</span>          <span class="mf">0.97916667</span>  <span class="mf">1.</span>        <span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>Our classifier has a good precision: most of the sevens that it
predicts are really sevens.</p>
<p>As predicting the most frequent never predicts sevens, precision is ill
defined. Scikit-learn puts it to zero</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">most_frequent</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">sevens</span><span class="p">,</span>
<div class="newline"></div>                      <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;precision&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p><strong>Recall</strong>: Recall counts the fraction of class 1 actually detected</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">sevens</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;recall&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.73333333</span>  <span class="mf">0.75</span>        <span class="mf">0.83050847</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>Our recall isn&#8217;t as good: we miss many sevens</p>
<p>But predicting the most frequent never predicts sevens:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">most_frequent</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">sevens</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;recall&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.</span>  <span class="mf">0.</span>  <span class="mf">0.</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p><strong>Note</strong>: Measuring only the precision without the recall makes no
sense, it is easy to maximize one at the cost of the other. Ideally,
classifiers should be compared on a precision at a given recall</p>
</div>
<div class="section" id="area-under-the-roc-curve">
<h3><a class="toc-backref" href="#id11">1.1.2.4. Area under the ROC curve</a><a class="headerlink" href="#area-under-the-roc-curve" title="Permalink to this headline">¶</a></h3>
<p>If the classifier provides a decision function that can be thresholded
to control false positives versus false negatives, the ROC curve
summarise the different tradeoffs that can be achieved by varying this
threshold.</p>
<p>Its Area Under the Curve (AUC) is a useful metric where 1 is perfect
prediction and .5 is chance, independently of class imbalance</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">sevens</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.97891975</span>  <span class="mf">0.99952072</span>  <span class="mf">0.99938681</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">most_frequent</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">sevens</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.5</span>  <span class="mf">0.5</span>  <span class="mf">0.5</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
</div>
<div class="section" id="average-precision">
<h3><a class="toc-backref" href="#id12">1.1.2.5. Average precision</a><a class="headerlink" href="#average-precision" title="Permalink to this headline">¶</a></h3>
<p>When the classifier exposes its unthresholded decision, another
interesting metric is the average precision for all recall. Compared to
ROC AUC it has a more linear behavior for very rare classes. Indeed,
with very rare classes, small changes in the ROC AUC may mean large
changes in terms of precision</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">sevens</span><span class="p">,</span>
<div class="newline"></div>                      <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;average_precision&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.95375779</span>  <span class="mf">0.98295732</span>  <span class="mf">0.98281818</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>Naive decisions are no longer at .5</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">most_frequent</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">sevens</span><span class="p">,</span>
<div class="newline"></div>                      <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;average_precision&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.1</span>         <span class="mf">0.10016694</span>  <span class="mf">0.09866221</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
</div>
<div class="section" id="multiclass-and-multilabel-settings">
<h3><a class="toc-backref" href="#id13">1.1.2.6. Multiclass and multilabel settings</a><a class="headerlink" href="#multiclass-and-multilabel-settings" title="Permalink to this headline">¶</a></h3>
<p>To simplify the discussion, we have reduced the problem to detecting
sevens, but maybe it is more interesting to predict the digit: a
10-class classification problem</p>
<p><strong>Accuracy</strong> The accuracy is naturally defined in such multiclass settings</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.89036545</span>  <span class="mf">0.88647746</span>  <span class="mf">0.90771812</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>The most frequent label is no longer a very interesting baseline</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">random_choice</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">()</span>
<div class="newline"></div><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">random_choice</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.10299003</span>  <span class="mf">0.10183639</span>  <span class="mf">0.12248322</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>Precision and recall need the notion of specific class to detect
(called positive class) and are not that easily defined in these
settings, hence ROC AUC cannot be easily computed.</p>
<p>These notions are however well defined in a multi-label problem.
In such a problem, the goal is to assign one or more labels to each
instance, as opposed to a multiclass. A multiclass problem can be
turned into a multilabel one, though the prediction will then be
slightly different</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelBinarizer</span>
<div class="newline"></div><span class="n">digit_labels</span> <span class="o">=</span> <span class="n">LabelBinarizer</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<div class="newline"></div><span class="k">print</span><span class="p">(</span><span class="n">digit_labels</span><span class="p">[:</span><span class="mi">15</span><span class="p">])</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
<div class="newline"></div> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]]</span>
<div class="newline"></div></pre></div>
</div>
<p>The ROC AUC can then be computed for each label</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digit_labels</span><span class="p">,</span>
<div class="newline"></div>                      <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.98443392</span>  <span class="mf">0.9904604</span>   <span class="mf">0.98368181</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>as well as the average precision</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digit_labels</span><span class="p">,</span>
<div class="newline"></div>                      <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;average_precision&#39;</span><span class="p">))</span>
<div class="newline"></div></pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="mf">0.93893199</span>  <span class="mf">0.94508469</span>  <span class="mf">0.93109864</span><span class="p">]</span>
<div class="newline"></div></pre></div>
</div>
<p>Note that the confusion between classes may not well be captured in
Such a measure, as in multiclass predictions are exclusive, and not
in multilabel.</p>
</div>
<div class="section" id="id1">
<h3><a class="toc-backref" href="#id14">1.1.2.7. Summary</a><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Class imbalance and the tradeoffs between accepting many misses or many
false detections are the things to keep in mind in classification.</p>
<p>In single-class settings, ROC AUC and average precision give nice
summaries to compare classifiers when the threshold can be varied. In
multiclass settings, this is harder, unless we are willing to consider
the problem as multiple single-class problems (one-vs-all).</p>
<hr class="docutils" />
<p><strong>Total running time of the script:</strong> ( 0 minutes  2.388 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-content-01-how-well-01-metrics-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/gaelvaroquaux/interpreting_ml_tuto/master?filepath=_downloads/01_metrics.ipynb"><img alt="https://static.mybinder.org/badge.svg" src="https://static.mybinder.org/badge.svg" width="150px" /></a>
</div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../_downloads/01_metrics.py" download=""><code class="xref download docutils literal"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">01_metrics.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../_downloads/01_metrics.ipynb" download=""><code class="xref download docutils literal"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">01_metrics.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
<p><div style="clear: both"></div></p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
	<div class="sidebartoc">
  <h3><a href="../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">1.1. Metrics to judge the sucess of a model</a><ul>
<li><a class="reference internal" href="#regression-settings">1.1.1. Regression settings</a><ul>
<li><a class="reference internal" href="#the-boston-housing-data">1.1.1.1. The Boston housing data</a></li>
<li><a class="reference internal" href="#explained-variance-vs-mean-square-error">1.1.1.2. Explained variance vs Mean Square Error</a></li>
<li><a class="reference internal" href="#mean-squared-error-versus-mean-absolute-error">1.1.1.3. Mean Squared Error versus Mean Absolute Error</a></li>
<li><a class="reference internal" href="#summary">1.1.1.4. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#classification-settings">1.1.2. Classification settings</a><ul>
<li><a class="reference internal" href="#the-digits-data">1.1.2.1. The digits data</a></li>
<li><a class="reference internal" href="#accuracy-and-its-shortcomings">1.1.2.2. Accuracy and its shortcomings</a></li>
<li><a class="reference internal" href="#precision-recall-and-their-shortcomings">1.1.2.3. Precision, recall, and their shortcomings</a></li>
<li><a class="reference internal" href="#area-under-the-roc-curve">1.1.2.4. Area under the ROC curve</a></li>
<li><a class="reference internal" href="#average-precision">1.1.2.5. Average precision</a></li>
<li><a class="reference internal" href="#multiclass-and-multilabel-settings">1.1.2.6. Multiclass and multilabel settings</a></li>
<li><a class="reference internal" href="#id1">1.1.2.7. Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>



    <div class="script_container">
    <script>
    (function() {
	var cx = '004523248466141510607:hgv2yimrahw';
	var gcse = document.createElement('script');
	gcse.type = 'text/javascript';
	gcse.async = true;
	gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
	    '//cse.google.com/cse.js?cx=' + cx;
	var s = document.getElementsByTagName('script')[0];
	s.parentNode.insertBefore(gcse, s);
    })();
    </script>
    <gcse:search></gcse:search>
    </div>

        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="02_cross_validation.html" title="1.2. Cross-validation: some gotchas"
             >next</a></li>
        <li class="right" >
          <a href="index.html" title="1. Measuring how well a model predicts"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">Tutorial</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >1. Measuring how well a model predicts</a> &#187;</li>
     
    <!-- Insert a menu in the navigation bar -->
    <li class="left">
	<!-- On click toggle the 'tip' on or off-->
	<a onclick="$('.tip').each(function (index, obj) {
			    collapse_tip_div(obj);
		    });
		    $('.tip').addClass('collapsed');
		    $('.left').addClass('transparent');">
	<img src="../../_static/minus.png"
         alt="Collapse to compact view" style="padding: 1ex;"/>
	<span class="hiddenlink">Collapse document to compact view</span>
    </a></li>

      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright .
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.5.6.
    </div>
  </body>
</html>